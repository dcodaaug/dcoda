# @package _group_

name: DIFFUSION

model: transformer # transformer or cnn
robot_name: 'bimanual'
agent_type: 'bimanual'

train_demo_path: "/home/markus/rlbench_data_v2_128/train/"

lr: 1e-4
weight_decay: 1e-4
betas: [0.9, 0.95]
demo_augmentation: True
demo_augmentation_every_n: 10

scheduler:
  name: cosine
  kwargs:
    T_max: ${framework.training_iterations}
    eta_min: 3e-5

camera_names: ${rlbench.cameras}


# (W, H)
image_size: [128, 128]

action_dim: 16
observation_horizon: 1
prev_action_horizon: 1
next_action_horizon: 10
num_queries: ${method.next_action_horizon} 
chunk_size: ${method.next_action_horizon}
prediction_horizon: ${method.next_action_horizon}

num_train_timesteps: 100
num_inference_timesteps: 100


ema_power: 0.995
vq: false
temporal_agg: false

cnn_kwargs:
  diffusion_step_embed_dim: 256
  down_dims: [256,512,1024]


transformer_kwargs:
  n_obs_steps: ${method.observation_horizon} # >1 not tested
  horizon: ${method.chunk_size}
  n_layer: 6
  n_cond_layers: 0  # >0: use transformer encoder for cond, otherwise use MLP
  n_head: 4
  n_emb: 512
  p_drop_emb: 0.0
  p_drop_attn: 0.1
  causal_attn: True
  time_as_cond: True
  obs_as_cond: True

# ..todo:: also set the following

+rlbench.episode_length: 400
+rlbench.arm_action_mode: JointPosition
+rlbench.action_mode: JointPositionActionMode
